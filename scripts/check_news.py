#!/usr/bin/env python3
"""
ç½‘ä¸Šå†²æµªè„šæœ¬ - ç»“åˆä¼˜åŒ–æœç´¢å’Œæµè§ˆå™¨æŠ“å–
æ–¹æ¡ˆ1: åˆå¹¶æœç´¢æŸ¥è¯¢ï¼ˆèŠ‚çœAPIè°ƒç”¨ï¼‰
æ–¹æ¡ˆ3: æµè§ˆå™¨è®¿é—®æ–°é—»ç½‘ç«™ï¼ˆä¸å—APIé™åˆ¶ï¼‰
"""
import json
from datetime import datetime
from pathlib import Path

# æ–°é—»ç½‘ç«™åˆ—è¡¨
NEWS_SITES = [
    {"name": "MIT Technology Review", "url": "https://www.technologyreview.com/", "topic": "AI"},
    {"name": "TechCrunch AI", "url": "https://techcrunch.com/category/artificial-intelligence/", "topic": "AI"},
    {"name": "The Verge AI", "url": "https://www.theverge.com/ai-artificial-intelligence", "topic": "AI"},
    {"name": "Polymarket Blog", "url": "https://polymarket.com/", "topic": "Polymarket"},
]

# åˆå¹¶æœç´¢æŸ¥è¯¢ï¼ˆèŠ‚çœAPIè°ƒç”¨ï¼‰
COMBINED_QUERIES = [
    "AI artificial intelligence breakthrough news latest",
    "technology innovation today"
]

# ç»“æœå­˜å‚¨æ–‡ä»¶
NEWS_LOG = "/root/clawd/memory/news_search_log.json"
STATE_FILE = "/root/clawd/memory/news_state.json"


def load_state():
    """åŠ è½½çŠ¶æ€"""
    try:
        if Path(STATE_FILE).exists():
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except:
        pass
    return {"seen_urls": [], "last_search_time": None, "last_browser_fetch": None}


def save_state(state):
    """ä¿å­˜çŠ¶æ€"""
    Path(STATE_FILE).parent.mkdir(parents=True, exist_ok=True)
    with open(STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(state, f, indent=2, ensure_ascii=False)


def should_search(state):
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ï¼ˆè·ç¦»ä¸Šæ¬¡3å°æ—¶ä»¥ä¸Šï¼‰"""
    if not state.get("last_search_time"):
        return True

    try:
        last_time = datetime.fromisoformat(state["last_search_time"])
        elapsed = (datetime.now() - last_time).total_seconds()
        return elapsed >= 3 * 3600  # 3å°æ—¶
    except:
        return True


def should_browser_fetch(state):
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æµè§ˆå™¨æŠ“å–ï¼ˆè·ç¦»ä¸Šæ¬¡1å°æ—¶ä»¥ä¸Šï¼‰"""
    if not state.get("last_browser_fetch"):
        return True

    try:
        last_time = datetime.fromisoformat(state["last_browser_fetch"])
        elapsed = (datetime.now() - last_time).total_seconds()
        return elapsed >= 1 * 3600  # 1å°æ—¶
    except:
        return True


def main():
    """ä¸»å‡½æ•°"""
    state = load_state()

    print("="*60)
    print("ğŸŒ ç½‘ä¸Šå†²æµªä»»åŠ¡")
    print(f"ğŸ“… æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

    # æ–¹æ¡ˆ1: ä¼˜åŒ–æœç´¢ç­–ç•¥
    if should_search(state):
        print("\nğŸ“‹ æ–¹æ¡ˆ1: åˆå¹¶æœç´¢æŸ¥è¯¢")
        print("æœç´¢ä¸»é¢˜:")
        for i, query in enumerate(COMBINED_QUERIES, 1):
            print(f"   {i}. {query}")
        print("âœ… å‡†å¤‡æ‰§è¡Œæœç´¢ï¼ˆå·²ä¼˜åŒ–ä¸º2ä¸ªæŸ¥è¯¢ï¼‰")
        state["last_search_time"] = datetime.now().isoformat()
    else:
        last_time = state.get("last_search_time", "æœªçŸ¥")
        print(f"\nâ° æœç´¢æœªåˆ°3å°æ—¶ï¼Œä¸Šæ¬¡: {last_time}")

    # æ–¹æ¡ˆ3: æµè§ˆå™¨æŠ“å–
    if should_browser_fetch(state):
        print("\nğŸŒ æ–¹æ¡ˆ3: æµè§ˆå™¨è®¿é—®æ–°é—»ç½‘ç«™")
        print("ç›®æ ‡ç½‘ç«™:")
        for site in NEWS_SITES:
            print(f"   - {site['name']}: {site['url']}")
        print("âœ… å‡†å¤‡æ‰§è¡Œæµè§ˆå™¨æŠ“å–")
        state["last_browser_fetch"] = datetime.now().isoformat()
    else:
        last_time = state.get("last_browser_fetch", "æœªçŸ¥")
        print(f"\nâ° æµè§ˆå™¨æŠ“å–æœªåˆ°1å°æ—¶ï¼Œä¸Šæ¬¡: {last_time}")

    # ä¿å­˜çŠ¶æ€
    save_state(state)

    print("\n" + "="*60)
    print("âœ… ä»»åŠ¡æ£€æŸ¥å®Œæˆ")
    print("="*60)


if __name__ == "__main__":
    main()
