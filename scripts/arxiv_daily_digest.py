#!/usr/bin/env python3
"""
ArXiv AI è®ºæ–‡æ¯æ—¥æ‘˜è¦è„šæœ¬
æ¯å¤©æ—©ä¸Š8ç‚¹å‘é€æœ€æ–°çš„AIè®ºæ–‡åˆ°æŒ‡å®šé‚®ç®±ï¼Œå¹¶å†™å…¥é£ä¹¦å¤šç»´è¡¨æ ¼
"""
import requests
import xml.etree.ElementTree as ET
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from email.utils import formataddr
import json
import os
from datetime import datetime, timedelta

# ========== é…ç½®åŒºåŸŸ ==========

# SMTP é…ç½®ï¼ˆä½¿ç”¨QQé‚®ç®±å‘é€ï¼‰
SMTP_SERVER = "smtp.qq.com"
SMTP_PORT = 465
SMTP_USER = "781291348@qq.com"
SMTP_PASS = "zklwmudvlnsabdce"

# æ”¶ä»¶äºº
RECIPIENT = "iamguod@163.com"

# arXiv é…ç½®
ARXIV_CATEGORIES = "cat:cs.AI+OR+cat:cs.LG+OR+cat:cs.CL+OR+cat:cs.CV"
MAX_PAPERS = 5  # æ¯å°é‚®ä»¶æœ€å¤š5ç¯‡

# æœ¬åœ°å­˜å‚¨
SENT_PAPERS_FILE = "/root/clawd/arxiv_sent_papers.json"
FEISHU_IMPORT_FILE = "/root/clawd/arxiv_feishu_import.md"

# é£ä¹¦å¤šç»´è¡¨æ ¼é…ç½®
FEISHU_APP_ID = "cli_a90aa0be57b81bd1"
FEISHU_APP_SECRET = "MfsbAnzRazZsuHgrYhT8HhsYSaw4nEwN"
FEISHU_APP_TOKEN = "L2pmbFDhja34HMsLAOgcSxYInGz"
FEISHU_TABLE_ID = "tbleOsazruYwyPKp"

# GLM ç¿»è¯‘ API é…ç½®
GLM_API_BASE = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
GLM_API_KEY = "cee1da60ac514048a4b8cc788a93f109.ga9IyuQhBjZ8ReK6"

# ========== å·¥å…·å‡½æ•° ==========

def load_sent_papers():
    """åŠ è½½å·²å‘é€çš„è®ºæ–‡IDåˆ—è¡¨"""
    if os.path.exists(SENT_PAPERS_FILE):
        try:
            with open(SENT_PAPERS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except:
            return set()
    return set()

def save_sent_papers(sent_papers):
    """ä¿å­˜å·²å‘é€çš„è®ºæ–‡IDåˆ—è¡¨"""
    with open(SENT_PAPERS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(sent_papers), f, ensure_ascii=False, indent=2)

def get_app_token():
    """è·å–é£ä¹¦ app_access_token"""
    url = f"https://open.feishu.cn/open-apis/auth/v3/app_access_token/internal"
    payload = {
        "app_id": FEISHU_APP_ID,
        "app_secret": FEISHU_APP_SECRET
    }
    resp = requests.post(url, json=payload)
    if resp.status_code == 200:
        return resp.json().get("app_access_token")
    else:
        print(f"è·å–é£ä¹¦ token å¤±è´¥: {resp.text}")
        return None

def batch_create_records(papers):
    """æ‰¹é‡åˆ›å»ºè®°å½•åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼"""
    token = get_app_token()
    if not token:
        return False

    headers = {"Authorization": f"Bearer {token}"}

    # ä½¿ç”¨ batch_create æ¥å£
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{FEISHU_APP_TOKEN}/tables/{FEISHU_TABLE_ID}/records/batch_create"

    # æ„å»ºè®°å½•æ•°ç»„
    records = []
    for paper in papers:
        record = {
            "fields": {
                "æ ‡é¢˜": paper['title'],
                "æ‘˜è¦": paper['summary'],
                "ä¸­æ–‡æ ‡é¢˜": paper.get('cn_title', ''),
                "ä¸­æ–‡æ‘˜è¦": paper.get('cn_abstract', ''),
                "é“¾æ¥": {"link": paper['link']},
                "å‘å¸ƒæ—¥æœŸ": int(datetime.now().timestamp() * 1000)
            }
        }
        records.append(record)

    payload = {"records": records}

    try:
        resp = requests.post(url, headers=headers, json=payload)
        if resp.status_code == 200:
            result = resp.json()
            if result.get("code") == 0:
                created_count = len(result.get("data", {}).get("records", []))
                print(f"âœ“ é£ä¹¦è¡¨æ ¼å†™å…¥æˆåŠŸ: {created_count} æ¡è®°å½•")
                return True
            else:
                print(f"âœ— é£ä¹¦è¡¨æ ¼å†™å…¥å¤±è´¥: {result}")
                return False
        else:
            print(f"âœ— é£ä¹¦è¡¨æ ¼å†™å…¥å¤±è´¥: HTTP {resp.status_code}")
            return False
    except Exception as e:
        print(f"âœ— é£ä¹¦è¡¨æ ¼å†™å…¥å¼‚å¸¸: {e}")
        return False

def translate_text_to_chinese(text, max_length=800):
    """ä½¿ç”¨ GLM API ç¿»è¯‘æ–‡æœ¬åˆ°ä¸­æ–‡"""
    if not GLM_API_KEY:
        return ""

    if len(text) > max_length:
        text = text[:max_length] + "..."

    try:
        headers = {
            "Authorization": f"Bearer {GLM_API_KEY}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": "glm-4-flash",
            "messages": [
                {
                    "role": "user",
                    "content": f"Please translate the following text to Chinese:\n\n{text}"
                }
            ],
            "temperature": 0.3
        }

        response = requests.post(GLM_API_BASE, headers=headers, json=payload, timeout=60)

        if response.status_code == 200:
            result = response.json()
            return result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
        else:
            return ""

    except Exception as e:
        print(f"ç¿»è¯‘å¼‚å¸¸: {e}")
        return ""

def fetch_arxiv_papers(days_back=1):
    """ä» arXiv è·å–æœ€æ–°çš„ AI è®ºæ–‡"""
    base_url = "http://export.arxiv.org/api/query?"
    query = f"search_query={ARXIV_CATEGORIES}&sortBy=submittedDate&sortOrder=descending&max_results=20"

    try:
        response = requests.get(base_url + query, timeout=30)
        response.raise_for_status()
        root = ET.fromstring(response.text)

        ns = {'atom': 'http://www.w3.org/2005/Atom', 'arxiv': 'http://arxiv.org/schemas/atom'}

        papers = []
        for entry in root.findall('atom:entry', ns):
            paper_id = entry.find('atom:id', ns).text.split('/abs/')[-1]
            title = entry.find('atom:title', ns).text.strip()
            summary = entry.find('atom:summary', ns).text.strip()
            published = entry.find('atom:published', ns).text
            link = entry.find('atom:link', ns).get('href')

            pub_date = datetime.strptime(published[:19], "%Y-%m-%dT%H:%M:%S")
            if pub_date < datetime.now() - timedelta(days=days_back):
                continue

            papers.append({
                'id': paper_id,
                'title': title,
                'summary': summary,
                'published': published,
                'link': link
            })

        return papers[:MAX_PAPERS * 2]

    except Exception as e:
        print(f"è·å– arXiv è®ºæ–‡å¤±è´¥: {e}")
        return []

def send_email(subject, content):
    """å‘é€é‚®ä»¶"""
    msg = MIMEMultipart()
    msg['From'] = formataddr(('ArXivæ—¥æŠ¥', SMTP_USER))
    msg['To'] = formataddr(('Man', RECIPIENT))
    msg['Subject'] = Header(subject, 'utf-8')

    msg.attach(MIMEText(content, 'plain', 'utf-8'))

    try:
        with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:
            server.login(SMTP_USER, SMTP_PASS)
            server.sendmail(SMTP_USER, [RECIPIENT], msg.as_string())
        print(f"âœ“ é‚®ä»¶å‘é€æˆåŠŸ: {subject}")
        return True
    except Exception as e:
        print(f"âœ— é‚®ä»¶å‘é€å¤±è´¥: {e}")
        return False

def format_paper(paper):
    """æ ¼å¼åŒ–å•ç¯‡è®ºæ–‡"""
    print(f"æ­£åœ¨å¤„ç†è®ºæ–‡ {paper['id']}...")
    title_cn = translate_text_to_chinese(paper['title'])
    abstract_cn = translate_text_to_chinese(paper['summary'])

    paper['cn_title'] = title_cn if title_cn else '[ç¿»è¯‘å¤±è´¥]'
    paper['cn_abstract'] = abstract_cn if abstract_cn else '[ç¿»è¯‘å¤±è´¥]'

    result = f"""
ã€è®ºæ–‡ {paper['id']}ã€‘

1ã€è®ºæ–‡æ ‡é¢˜ï¼ˆè‹±æ–‡+ä¸­æ–‡ç¿»è¯‘ï¼‰
{paper['title']}
{title_cn if title_cn else '[ç¿»è¯‘å¤±è´¥]'}

2ã€è®ºæ–‡æ‘˜è¦ï¼ˆè‹±æ–‡+ä¸­æ–‡ï¼‰
{paper['summary']}
{abstract_cn if abstract_cn else '[ç¿»è¯‘å¤±è´¥]'}

é“¾æ¥: {paper['link']}
"""
    return result

def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'='*60}")
    print(f"ArXiv AI è®ºæ–‡æ—¥æŠ¥ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

    # åŠ è½½å·²å‘é€è®°å½•
    sent_papers = load_sent_papers()

    # è·å–æ–°è®ºæ–‡
    print("æ­£åœ¨è·å– arXiv è®ºæ–‡...")
    all_papers = fetch_arxiv_papers(days_back=7)

    if not all_papers:
        print("æ²¡æœ‰è·å–åˆ°è®ºæ–‡")
        return

    print(f"è·å–åˆ° {len(all_papers)} ç¯‡è®ºæ–‡")

    # è¿‡æ»¤å·²å‘é€çš„
    new_papers = [p for p in all_papers if p['id'] not in sent_papers]

    if not new_papers:
        print("æ²¡æœ‰æ–°çš„è®ºæ–‡éœ€è¦å‘é€")
        return

    new_papers = new_papers[:MAX_PAPERS]
    print(f"ç­›é€‰åå‘é€ {len(new_papers)} ç¯‡è®ºæ–‡")

    # ç¿»è¯‘å¹¶å†™å…¥é£ä¹¦è¡¨æ ¼
    print("\næ­£åœ¨ç¿»è¯‘å¹¶å†™å…¥é£ä¹¦å¤šç»´è¡¨æ ¼...")
    for paper in new_papers:
        title_cn = translate_text_to_chinese(paper['title'])
        abstract_cn = translate_text_to_chinese(paper['summary'])
        paper['cn_title'] = title_cn if title_cn else '[ç¿»è¯‘å¤±è´¥]'
        paper['cn_abstract'] = abstract_cn if abstract_cn else '[ç¿»è¯‘å¤±è´¥]'

    batch_create_records(new_papers)

    # æ„å»ºé‚®ä»¶å†…å®¹
    content = f"""ğŸ¤– ArXiv AI è®ºæ–‡æ—¥æŠ¥
{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}

ä»¥ä¸‹æ˜¯ä»Šå¤©çš„AIé¢†åŸŸçƒ­ç‚¹è®ºæ–‡ï¼š

"""

    for i, paper in enumerate(new_papers, 1):
        content += format_paper(paper)
        if i < len(new_papers):
            content += "\n" + "-"*60 + "\n"

    content += "\n---\nç”±å¤§è™å“¥è‡ªåŠ¨å‘é€\n"

    # å‘é€é‚®ä»¶
    subject = f"ğŸ“š ArXiv AIè®ºæ–‡æ—¥æŠ¥ - {datetime.now().strftime('%Y-%m-%d')}"
    if send_email(subject, content):
        sent_papers.update(p['id'] for p in new_papers)
        save_sent_papers(sent_papers)
        print("\nâœ“ é‚®ä»¶å‘é€æˆåŠŸï¼Œå·²æ›´æ–°å·²å‘é€è®°å½•")
        print("âœ“ æ‰€æœ‰è®ºæ–‡å·²å†™å…¥é£ä¹¦å¤šç»´è¡¨æ ¼")
    else:
        print("âœ— é‚®ä»¶å‘é€å¤±è´¥")

if __name__ == "__main__":
    main()
